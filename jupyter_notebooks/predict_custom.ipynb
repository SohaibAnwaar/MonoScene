{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a970f48a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Predict Your Custom image with the help of this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from helper import *\n",
    "import sys\n",
    "import csv\n",
    "from PIL import Image\n",
    "from monoscene.models.monoscene import MonoScene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b1423",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/monoscene/MonoScene/trained_models/monoscene_kitti.ckpt\"\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "\n",
    "model = MonoScene.load_from_checkpoint(\n",
    "        model_path,\n",
    "        dataset=\"kitti\",\n",
    "        n_classes=20,\n",
    "        feature = 64,\n",
    "        project_scale = 2,\n",
    "        full_scene_size = (256, 256, 32),\n",
    "    )\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "img_W, img_H = 1220, 370"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a06aa",
   "metadata": {},
   "source": [
    "# Inference Custom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    img = np.array(img, dtype=np.float32, copy=False) / 255.0\n",
    "\n",
    "    normalize_rgb = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    img = normalize_rgb(img)\n",
    "   \n",
    "    batch = get_projections(img_W, img_H)\n",
    "    batch[\"img\"] = img\n",
    "    \n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].unsqueeze(0).cuda()\n",
    "\n",
    "    pred = model(batch)\n",
    "    y_pred = torch.softmax(pred[\"ssc_logit\"], dim=1).detach().cpu().numpy()\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    fig = draw(y_pred.squeeze(), batch['fov_mask_1'].cpu())\n",
    "    return fig\n",
    "   \n",
    "color_image_path = \"./input_images/000295.jpg\"\n",
    "image = Image.open(color_image_path)\n",
    "predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c25298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monoscene",
   "language": "python",
   "name": "monoscene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
